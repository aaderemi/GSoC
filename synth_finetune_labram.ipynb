{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaderemi/GSoC/blob/main/synth_finetune_labram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "n75gswAOfJhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "i6cxAumOOWiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r drive/MyDrive/npy_synthetic_ersp.zip npy_synthetic_data.zip\n",
        "!unzip npy_synthetic_data.zip"
      ],
      "metadata": {
        "id": "kkZx4J7DOE3Q",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp drive/MyDrive/labram.zip labram.zip\n",
        "!unzip labram.zip"
      ],
      "metadata": {
        "id": "4MGx3QTKxxRH",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX\n",
        "!pip install pyhealth"
      ],
      "metadata": {
        "id": "MU2PnVdRd5Nu",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "!pip install mne\n",
        "!pip install timm"
      ],
      "metadata": {
        "id": "4G98hFs3O0IW",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install captum"
      ],
      "metadata": {
        "id": "R2rJYPKdxA7V",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp drive/MyDrive/synthetic_mod.zip synthetic_mod.zip\n",
        "!unzip synthetic_mod.zip"
      ],
      "metadata": {
        "id": "4AZXDn5NDUEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/LaBraM')\n",
        "import json"
      ],
      "metadata": {
        "id": "GsA_oSzlUcLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqU8keB4GIPR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import wandb\n",
        "from rich import print\n",
        "from safetensors.torch import load_file\n",
        "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import KFold, LeaveOneGroupOut\n",
        "from transformers import get_scheduler\n",
        "import mne\n",
        "import sklearn\n",
        "from mne.filter import filter_data\n",
        "from sklearn.cluster import KMeans\n",
        "from transformers import set_seed\n",
        "import math\n",
        "import timm\n",
        "import copy\n",
        "import captum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjn3v6RqGIPe"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed_value):\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed_value)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed_value)\n",
        "        torch.cuda.manual_seed_all(seed_value)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    print(f\"\\nRandom seed value is initialized to: \", seed_value)\n",
        "\n",
        "seed = 0\n",
        "seed_everything(seed)\n",
        "np.set_printoptions(precision=4)\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'\n",
        "\n",
        "BLAES_data_path = \"/home/zeydabadi/BLAES/BIP\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#set seed with transformers set seed\n",
        "set_seed(42)\n",
        "batch_size = 64\n",
        "num_epochs = 50\n",
        "\n",
        "Fs = 500 #sampling frequency\n",
        "num_channels = 19 #number of channels\n",
        "\n",
        "BLAES_data_path = \"/content/content/train\"\n",
        "model_path  = \"/content/labram_pt_out/model_5.pth\"\n",
        "decay = 0.9999\n",
        "patch_size = 500\n",
        "embed_dim = 500\n",
        "out_chans = embed_dim\n",
        "num_classes = 4\n",
        "\n",
        "max_value = 3.192746112311605 #maximum value in dataset for erp signals."
      ],
      "metadata": {
        "id": "26FKp0D-0Xxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bldlob44OfZ4"
      },
      "outputs": [],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XvgVTc2MOYe"
      },
      "outputs": [],
      "source": [
        "class AverageMeter:\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Computing device is: \", device)"
      ],
      "metadata": {
        "id": "E9O51NHt1MIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNk0BHv3GIPn"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Computing device is: \", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kj1zKfHjGIPo"
      },
      "outputs": [],
      "source": [
        "def custom_balanced_accuracy(preds, targets):\n",
        "    \"\"\"\n",
        "    Calculate the balanced accuracy score for PyTorch tensors.\n",
        "\n",
        "    Args:\n",
        "    - preds (torch.Tensor): The predicted labels.\n",
        "    - targets (torch.Tensor): The true labels.\n",
        "\n",
        "    Returns:\n",
        "    - torch.Tensor: The balanced accuracy score.\n",
        "    \"\"\"\n",
        "    unique_labels = torch.unique(targets)\n",
        "    acc_per_class = torch.zeros(len(unique_labels))\n",
        "    for i, label in enumerate(unique_labels):\n",
        "        correct = preds[targets == label] == label\n",
        "        acc_per_class[i] = correct.float().mean()\n",
        "    balanced_acc = acc_per_class.mean()\n",
        "    return balanced_acc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import  accuracy_score"
      ],
      "metadata": {
        "id": "uvFQ_tvJmsOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ScFfXmCGIPo"
      },
      "outputs": [],
      "source": [
        "def training(train_loader, model, criterion, optimizer, scheduler, device):\n",
        "    \"\"\"\n",
        "    Train a model.\n",
        "\n",
        "    Args:\n",
        "    - train_loader (torch.utils.data.DataLoader): The training data loader.\n",
        "    - model (torch.nn.Module): The model to train.\n",
        "    - criterion (torch.nn.Module): The loss function.\n",
        "    - optimizer (torch.optim.Optimizer): The optimizer.\n",
        "    - scheduler (torch.optim.lr_scheduler._LRScheduler): The learning rate scheduler.\n",
        "    - device (torch.device): The device to run training on.\n",
        "\n",
        "    Returns:\n",
        "    - dict: A dictionary containing the average loss and accuracy.\n",
        "    \"\"\"\n",
        "    # print('\\nTraining...')\n",
        "    avg_meters = {\"loss\": AverageMeter(), \"acc\": AverageMeter()}\n",
        "\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    model_ema = timm.utils.ModelEma(model, decay=decay, device=device)\n",
        "    #print(\"Number of bacthes (training): \", len(train_loader))\n",
        "\n",
        "\n",
        "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
        "        data, labels = data.float().to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        try:\n",
        "            output = model(data)\n",
        "            loss = criterion(output, labels)\n",
        "            if torch.isnan(loss):\n",
        "                print(f\"\\nNaN loss encountered in batch {batch_idx} !!!!\")\n",
        "                continue  # Skip this batch\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            #torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) did not use gradient clipping while testing\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()  # Correct placement for OneCycleLR scheduler, inside the batch loop\n",
        "            model_ema.update(model)\n",
        "\n",
        "            # Calculate the accuracy.\n",
        "        except Exception as e:\n",
        "            print(\n",
        "                f\"\\nAn error occurred during training in batch {batch_idx}: {e}\")\n",
        "            continue\n",
        "\n",
        "        avg_meters[\"loss\"].update(loss.item(), data.size(0))\n",
        "\n",
        "        #Sklearn balanced accuracy\n",
        "        #acc = balanced_accuracy_score(labels.detach().cpu(), output.argmax(dim=-1).detach().cpu())\n",
        "        #acc = custom_balanced_accuracy(output.argmax(dim=-1).detach().cpu(), labels.detach().cpu())\n",
        "        acc = accuracy_score(labels.detach().cpu(), output.argmax(dim=-1).detach().cpu())\n",
        "        avg_meters[\"acc\"].update(acc.item(), data.size(0))\n",
        "\n",
        "    # print(f'\\nEnd of Training - Average Loss: {avg_meters[\"loss\"].avg}, Average Accuracy: {avg_meters[\"acc\"].avg}')\n",
        "    return {\"loss\": avg_meters[\"loss\"].avg, \"acc\": avg_meters[\"acc\"].avg}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kAgSml6MTfD"
      },
      "outputs": [],
      "source": [
        "def validation(validation_loader, model, criterion, device):\n",
        "    \"\"\"\n",
        "    Validate a model.\n",
        "\n",
        "    Args:\n",
        "    - validation_loader (torch.utils.data.DataLoader): The validation data loader.\n",
        "    - model (torch.nn.Module): The model to validate.\n",
        "    - criterion (torch.nn.Module): The loss function.\n",
        "    - device (torch.device): The device to run validation on.\n",
        "\n",
        "    Returns:\n",
        "    - dict: A dictionary containing the average loss and accuracy.\n",
        "    \"\"\"\n",
        "    # print(\"\\nValidating...\")\n",
        "    avg_meters = {\"loss\": AverageMeter(), \"acc\": AverageMeter()}\n",
        "\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    #print(\"Number of bacthes (validation): \", len(validation_loader))\n",
        "\n",
        "    try:\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (data, labels) in enumerate(validation_loader):\n",
        "                # No need to check for batch size if DataLoader is set to drop_last=True\n",
        "                data, labels = data.float().to(device), labels.to(device)\n",
        "\n",
        "                # Make prediction.\n",
        "                output = model(data)\n",
        "\n",
        "                # Calculate the loss.\n",
        "                loss = criterion(output, labels)\n",
        "                avg_meters[\"loss\"].update(loss.item(), data.size(0))\n",
        "\n",
        "                # Calculate the accuracy.\n",
        "                #Sklearn balanced accuracy\n",
        "                #acc = balanced_accuracy_score(labels.detach().cpu(), output.argmax(dim=-1).detach().cpu())\n",
        "                #acc = custom_balanced_accuracy(output.argmax(dim=-1).detach().cpu(), labels.detach().cpu())\n",
        "                acc = accuracy_score(labels.detach().cpu(), output.argmax(dim=-1).detach().cpu())\n",
        "                avg_meters[\"acc\"].update(acc.item(), data.size(0))\n",
        "\n",
        "        # print(f'\\nAverage Validation Loss: {avg_meters[\"loss\"].avg}, Average Validation Accuracy: {avg_meters[\"acc\"].avg}')\n",
        "        return {\"loss\": avg_meters[\"loss\"].avg, \"acc\": avg_meters[\"acc\"].avg}\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn error occurred during validation: {e}\")\n",
        "        return {\"loss\": None, \"acc\": None}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KduvYlfmYQCH"
      },
      "source": [
        "# SSL\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "12WVTC7DS5sW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KO0fhEIb4ftE"
      },
      "outputs": [],
      "source": [
        "def list_files_with_extension(root_folder, extension):\n",
        "    \"\"\"\n",
        "    List all files with a specific extension in a folder and its subfolders.\n",
        "\n",
        "    Parameters:\n",
        "    - root_folder (str): The root folder to start the search.\n",
        "    - extension (str): The file extension to look for (e.g., '.txt').\n",
        "\n",
        "    Returns:\n",
        "    - List of file paths with the specified extension.\n",
        "    \"\"\"\n",
        "    matching_files = []\n",
        "    walk_list = list(os.walk(root_folder))\n",
        "    sorted_walk_list = sorted(walk_list, key=lambda x: x[0])\n",
        "\n",
        "    # Traverse the directory tree\n",
        "    for dirpath, dirnames, filenames in sorted_walk_list:\n",
        "        for filename in filenames:\n",
        "            if filename.endswith(extension):\n",
        "                full_path = os.path.join(dirpath, filename)\n",
        "                matching_files.append(full_path)\n",
        "\n",
        "    return matching_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNkZ_6uzZ0o_"
      },
      "outputs": [],
      "source": [
        "# im using dataset class from shared file\n",
        "class EEGDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, items):\n",
        "      self.items = items\n",
        "      np.random.shuffle(self.items)\n",
        "      # self.items = self.filter_valid_files(all_items)\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.items)\n",
        "\n",
        "  def get_filename(self, idx):\n",
        "      return self.items[idx]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      file_id = self.items[idx]\n",
        "      data = np.load(file_id)/max_value #normalize\n",
        "      data = torch.tensor(data, dtype = torch.float32)\n",
        "\n",
        "      data = data.reshape(19, -1, patch_size)\n",
        "\n",
        "      label = int(file_id.split('/')[-2].split('_')[0][-1])\n",
        "\n",
        "      return data, torch.tensor(label-1, dtype = torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class1_files = list_files_with_extension(\"/content/train/class1_500Hz_23dB_ersp_epochs\", '.npy')\n",
        "class2_files = list_files_with_extension(\"/content/train/class2_500Hz_23dB_ersp_epochs\", '.npy')\n",
        "class3_files = list_files_with_extension(\"/content/train/class3_500Hz_23dB_ersp_epochs\", '.npy')\n",
        "class4_files = list_files_with_extension(\"/content/train/class4_500Hz_23dB_ersp_epochs\", '.npy')"
      ],
      "metadata": {
        "id": "q4WqEGsllkYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(class1_files), len(class2_files), len(class3_files), len(class4_files)"
      ],
      "metadata": {
        "id": "k72a-LZplwvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_items = class1_files[:500]+class2_files[:500]+class3_files[:500]+class4_files[:500]\n",
        "\n",
        "#+class3_files[:500]+class4_files[:500]\n",
        "val_items = class1_files[1000:1100]+class2_files[1000:1100]+class3_files[1000:1100]+class4_files[1000:1100]\n",
        "\n",
        "#+class3_files[500:600]+class4_files[500:600]"
      ],
      "metadata": {
        "id": "yybVjBOgmDsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = EEGDataset(train_items)\n",
        "val_ds = EEGDataset(val_items)"
      ],
      "metadata": {
        "id": "iBB7XzgEZ_2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_ds), len(val_ds)"
      ],
      "metadata": {
        "id": "FeAWmogHbI9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.items[0], val_ds.items[0]"
      ],
      "metadata": {
        "id": "4dn7b1kVbP97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[0][1], val_ds[0][1]"
      ],
      "metadata": {
        "id": "EWU0ATXzbNcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "from timm.models.layers import drop_path, to_2tuple, trunc_normal_\n",
        "from timm.models.registry import register_model\n",
        "from einops import rearrange\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "def _cfg(url='', **kwargs):\n",
        "    return {\n",
        "        'url': url,\n",
        "        'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': None,\n",
        "        'crop_pct': .9, 'interpolation': 'bicubic',\n",
        "        'mean': (0.5, 0.5, 0.5), 'std': (0.5, 0.5, 0.5),\n",
        "        **kwargs\n",
        "    }\n",
        "\n",
        "\n",
        "class DropPath(nn.Module):\n",
        "    \"\"\"Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).\n",
        "    \"\"\"\n",
        "    def __init__(self, drop_prob=None):\n",
        "        super(DropPath, self).__init__()\n",
        "        self.drop_prob = drop_prob\n",
        "\n",
        "    def forward(self, x):\n",
        "        return drop_path(x, self.drop_prob, self.training)\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        return 'p={}'.format(self.drop_prob)\n",
        "\n",
        "\n",
        "class Mlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
        "        super().__init__()\n",
        "        out_features = out_features or in_features\n",
        "        hidden_features = hidden_features or in_features\n",
        "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
        "        self.act = act_layer()\n",
        "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        # x = self.drop(x)\n",
        "        # commit this for the orignal BERT implement\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(\n",
        "            self, dim, num_heads=8, qkv_bias=False, qk_norm=None, qk_scale=None, attn_drop=0.,\n",
        "            proj_drop=0., window_size=None, attn_head_dim=None):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        if attn_head_dim is not None:\n",
        "            head_dim = attn_head_dim\n",
        "        all_head_dim = head_dim * self.num_heads\n",
        "        self.scale = qk_scale or head_dim ** -0.5\n",
        "\n",
        "        self.qkv = nn.Linear(dim, all_head_dim * 3, bias=False)\n",
        "        if qkv_bias:\n",
        "            self.q_bias = nn.Parameter(torch.zeros(all_head_dim))\n",
        "            self.v_bias = nn.Parameter(torch.zeros(all_head_dim))\n",
        "        else:\n",
        "            self.q_bias = None\n",
        "            self.v_bias = None\n",
        "\n",
        "        if qk_norm is not None:\n",
        "            self.q_norm = qk_norm(head_dim)\n",
        "            self.k_norm = qk_norm(head_dim)\n",
        "        else:\n",
        "            self.q_norm = None\n",
        "            self.k_norm = None\n",
        "\n",
        "        if window_size:\n",
        "            self.window_size = window_size\n",
        "            self.num_relative_distance = (2 * window_size[0] - 1) * (2 * window_size[1] - 1) + 3\n",
        "            self.relative_position_bias_table = nn.Parameter(\n",
        "                torch.zeros(self.num_relative_distance, num_heads))  # 2*Wh-1 * 2*Ww-1, nH\n",
        "            # cls to token & token 2 cls & cls to cls\n",
        "\n",
        "            # get pair-wise relative position index for each token inside the window\n",
        "            coords_h = torch.arange(window_size[0])\n",
        "            coords_w = torch.arange(window_size[1])\n",
        "            coords = torch.stack(torch.meshgrid([coords_h, coords_w]))  # 2, Wh, Ww\n",
        "            coords_flatten = torch.flatten(coords, 1)  # 2, Wh*Ww\n",
        "            relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]  # 2, Wh*Ww, Wh*Ww\n",
        "            relative_coords = relative_coords.permute(1, 2, 0).contiguous()  # Wh*Ww, Wh*Ww, 2\n",
        "            relative_coords[:, :, 0] += window_size[0] - 1  # shift to start from 0\n",
        "            relative_coords[:, :, 1] += window_size[1] - 1\n",
        "            relative_coords[:, :, 0] *= 2 * window_size[1] - 1\n",
        "            relative_position_index = \\\n",
        "                torch.zeros(size=(window_size[0] * window_size[1] + 1, ) * 2, dtype=relative_coords.dtype)\n",
        "            relative_position_index[1:, 1:] = relative_coords.sum(-1)  # Wh*Ww, Wh*Ww\n",
        "            relative_position_index[0, 0:] = self.num_relative_distance - 3\n",
        "            relative_position_index[0:, 0] = self.num_relative_distance - 2\n",
        "            relative_position_index[0, 0] = self.num_relative_distance - 1\n",
        "\n",
        "            self.register_buffer(\"relative_position_index\", relative_position_index)\n",
        "        else:\n",
        "            self.window_size = None\n",
        "            self.relative_position_bias_table = None\n",
        "            self.relative_position_index = None\n",
        "\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.proj = nn.Linear(all_head_dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "\n",
        "    def forward(self, x, rel_pos_bias=None, return_attention=False, return_qkv=False):\n",
        "        B, N, C = x.shape\n",
        "        qkv_bias = None\n",
        "        if self.q_bias is not None:\n",
        "            qkv_bias = torch.cat((self.q_bias, torch.zeros_like(self.v_bias, requires_grad=False), self.v_bias))\n",
        "        # qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        qkv = F.linear(input=x, weight=self.qkv.weight, bias=qkv_bias)\n",
        "        qkv = qkv.reshape(B, N, 3, self.num_heads, -1).permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]   # make torchscript happy (cannot use tensor as tuple) (B, H, N, C)\n",
        "        if self.q_norm is not None:\n",
        "            q = self.q_norm(q).type_as(v)\n",
        "        if self.k_norm is not None:\n",
        "            k = self.k_norm(k).type_as(v)\n",
        "\n",
        "        q = q * self.scale\n",
        "        attn = (q @ k.transpose(-2, -1))\n",
        "\n",
        "        if self.relative_position_bias_table is not None:\n",
        "            relative_position_bias = \\\n",
        "                self.relative_position_bias_table[self.relative_position_index.view(-1)].view(\n",
        "                    self.window_size[0] * self.window_size[1] + 1,\n",
        "                    self.window_size[0] * self.window_size[1] + 1, -1)  # Wh*Ww,Wh*Ww,nH\n",
        "            relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous()  # nH, Wh*Ww, Wh*Ww\n",
        "            attn = attn + relative_position_bias.unsqueeze(0)\n",
        "\n",
        "        if rel_pos_bias is not None:\n",
        "            attn = attn + rel_pos_bias\n",
        "\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        if return_attention:\n",
        "            return attn\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, -1)\n",
        "\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "\n",
        "        if return_qkv:\n",
        "            return x, qkv\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_norm=None, qk_scale=None, drop=0., attn_drop=0.,\n",
        "                 drop_path=0., init_values=None, act_layer=nn.GELU, norm_layer=nn.LayerNorm,\n",
        "                 window_size=None, attn_head_dim=None):\n",
        "        super().__init__()\n",
        "        self.norm1 = norm_layer(dim)\n",
        "        self.attn = Attention(\n",
        "            dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_norm=qk_norm, qk_scale=qk_scale,\n",
        "            attn_drop=attn_drop, proj_drop=drop, window_size=window_size, attn_head_dim=attn_head_dim)\n",
        "        # NOTE: drop path for stochastic depth, we shall see if this is better than dropout here\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
        "        self.norm2 = norm_layer(dim)\n",
        "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
        "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
        "\n",
        "        if init_values > 0:\n",
        "            self.gamma_1 = nn.Parameter(init_values * torch.ones((dim)),requires_grad=True)\n",
        "            self.gamma_2 = nn.Parameter(init_values * torch.ones((dim)),requires_grad=True)\n",
        "        else:\n",
        "            self.gamma_1, self.gamma_2 = None, None\n",
        "\n",
        "    def forward(self, x, rel_pos_bias=None, return_attention=False, return_qkv=False):\n",
        "        if return_attention:\n",
        "            return self.attn(self.norm1(x), rel_pos_bias=rel_pos_bias, return_attention=True)\n",
        "        if return_qkv:\n",
        "            y, qkv = self.attn(self.norm1(x), rel_pos_bias=rel_pos_bias, return_qkv=return_qkv)\n",
        "            x = x + self.drop_path(self.gamma_1 * y)\n",
        "            x = x + self.drop_path(self.gamma_2 * self.mlp(self.norm2(x)))\n",
        "            return x, qkv\n",
        "\n",
        "        if self.gamma_1 is None:\n",
        "            x = x + self.drop_path(self.attn(self.norm1(x), rel_pos_bias=rel_pos_bias))\n",
        "            x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
        "        else:\n",
        "            x = x + self.drop_path(self.gamma_1 * self.attn(self.norm1(x), rel_pos_bias=rel_pos_bias))\n",
        "            x = x + self.drop_path(self.gamma_2 * self.mlp(self.norm2(x)))\n",
        "        return x\n",
        "\n",
        "\n",
        "class PatchEmbed(nn.Module):\n",
        "    \"\"\" EEG to Patch Embedding\n",
        "    \"\"\"\n",
        "    def __init__(self, EEG_size=2000, patch_size=200, in_chans=1, embed_dim=200):\n",
        "        super().__init__()\n",
        "        # EEG_size = to_2tuple(EEG_size)\n",
        "        # patch_size = to_2tuple(patch_size)\n",
        "        num_patches = 62 * (EEG_size // patch_size)\n",
        "        self.patch_shape = (1, EEG_size // patch_size)\n",
        "        self.EEG_size = EEG_size\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patches = num_patches\n",
        "\n",
        "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=(1, patch_size), stride=(1, patch_size))\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        B, C, H, W = x.shape\n",
        "        x = self.proj(x).flatten(2).transpose(1, 2)\n",
        "        return x\n",
        "\n",
        "\n",
        "class TemporalConv(nn.Module):\n",
        "    \"\"\" Image to Patch Embedding\n",
        "    \"\"\"\n",
        "    def __init__(self, in_chans=1, out_chans=8):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_chans, out_chans, kernel_size=(1, 15), stride=(1, 8), padding=(0, 7))\n",
        "        self.gelu1 = nn.GELU()\n",
        "        self.norm1 = nn.GroupNorm(4, out_chans)\n",
        "        self.conv2 = nn.Conv2d(out_chans, out_chans, kernel_size=(1, 3), padding=(0, 1))\n",
        "        self.gelu2 = nn.GELU()\n",
        "        self.norm2 = nn.GroupNorm(4, out_chans)\n",
        "        self.conv3 = nn.Conv2d(out_chans, out_chans, kernel_size=(1, 3), padding=(0, 1))\n",
        "        self.norm3 = nn.GroupNorm(4, out_chans)\n",
        "        self.gelu3 = nn.GELU()\n",
        "\n",
        "        self.pooling = nn.AdaptiveAvgPool2d((None, 1))\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        x = rearrange(x, 'B N A T -> B (N A) T')\n",
        "        B, NA, T = x.shape\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.gelu1(self.norm1(self.conv1(x)))\n",
        "        x = self.gelu2(self.norm2(self.conv2(x)))\n",
        "        x = self.gelu3(self.norm3(self.conv3(x)))\n",
        "        #x = rearrange(x, 'B C NA T -> B NA (T C)')\n",
        "        x = self.pooling(x)\n",
        "        x = x.squeeze(-1).transpose(1, 2)\n",
        "        #print(x.shape)\n",
        "        return x\n",
        "\n",
        "\n",
        "class NeuralTransformer(nn.Module):\n",
        "    def __init__(self, EEG_size=1600, patch_size=200, in_chans=1, out_chans=8, num_classes=1000, embed_dim=200, depth=12,\n",
        "                 num_heads=10, mlp_ratio=4., qkv_bias=False, qk_norm=None, qk_scale=None, drop_rate=0., attn_drop_rate=0.,\n",
        "                 drop_path_rate=0., norm_layer=nn.LayerNorm, init_values=None,\n",
        "                 use_abs_pos_emb=True, use_rel_pos_bias=False, use_shared_rel_pos_bias=False,\n",
        "                 use_mean_pooling=True, init_scale=0.001, **kwargs):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.num_features = self.embed_dim = embed_dim  # num_features for consistency with other models\n",
        "\n",
        "        # To identify whether it is neural tokenizer or neural decoder.\n",
        "        # For the neural decoder, use linear projection (PatchEmbed) to project codebook dimension to hidden dimension.\n",
        "        # Otherwise, use TemporalConv to extract temporal features from EEG signals.\n",
        "        self.patch_embed = TemporalConv(out_chans=out_chans) if in_chans == 1 else PatchEmbed(EEG_size=EEG_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim)\n",
        "        self.time_window = EEG_size // patch_size\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
        "        # self.mask_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
        "        if use_abs_pos_emb:\n",
        "            self.pos_embed = nn.Parameter(torch.zeros(1, 128 + 1, embed_dim), requires_grad=True)\n",
        "        else:\n",
        "            self.pos_embed = None\n",
        "        self.time_embed = nn.Parameter(torch.zeros(1, 60, embed_dim), requires_grad=True)\n",
        "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
        "\n",
        "        self.rel_pos_bias = None\n",
        "\n",
        "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, depth)]  # stochastic depth decay rule\n",
        "        self.use_rel_pos_bias = use_rel_pos_bias\n",
        "        self.blocks = nn.ModuleList([\n",
        "            Block(\n",
        "                dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_norm=qk_norm, qk_scale=qk_scale,\n",
        "                drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr[i], norm_layer=norm_layer,\n",
        "                init_values=init_values, window_size=None)\n",
        "            for i in range(depth)])\n",
        "        self.norm = nn.Identity() if use_mean_pooling else norm_layer(embed_dim)\n",
        "        self.fc_norm = norm_layer(embed_dim) if use_mean_pooling else None\n",
        "        self.head = nn.Linear(embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n",
        "\n",
        "        if self.pos_embed is not None:\n",
        "            trunc_normal_(self.pos_embed, std=.02)\n",
        "        if self.time_embed is not None:\n",
        "            trunc_normal_(self.time_embed, std=.02)\n",
        "        trunc_normal_(self.cls_token, std=.02)\n",
        "        # trunc_normal_(self.mask_token, std=.02)\n",
        "        if isinstance(self.head, nn.Linear):\n",
        "            trunc_normal_(self.head.weight, std=.02)\n",
        "        self.apply(self._init_weights)\n",
        "        self.fix_init_weight()\n",
        "\n",
        "        if isinstance(self.head, nn.Linear):\n",
        "            self.head.weight.data.mul_(init_scale)\n",
        "            self.head.bias.data.mul_(init_scale)\n",
        "\n",
        "    def fix_init_weight(self):\n",
        "        def rescale(param, layer_id):\n",
        "            param.div_(math.sqrt(2.0 * layer_id))\n",
        "\n",
        "        for layer_id, layer in enumerate(self.blocks):\n",
        "            rescale(layer.attn.proj.weight.data, layer_id + 1)\n",
        "            rescale(layer.mlp.fc2.weight.data, layer_id + 1)\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            trunc_normal_(m.weight, std=.02)\n",
        "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.LayerNorm):\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "            nn.init.constant_(m.weight, 1.0)\n",
        "\n",
        "    def get_num_layers(self):\n",
        "        return len(self.blocks)\n",
        "\n",
        "    @torch.jit.ignore\n",
        "    def no_weight_decay(self):\n",
        "        return {'pos_embed', 'cls_token', 'time_embed'}\n",
        "\n",
        "    def get_classifier(self):\n",
        "        return self.head\n",
        "\n",
        "    def reset_classifier(self, num_classes, global_pool=''):\n",
        "        self.num_classes = num_classes\n",
        "        self.head = nn.Linear(self.embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n",
        "\n",
        "    def forward_features(self, x, input_chans=None, return_patch_tokens=False, return_all_tokens=False, **kwargs):\n",
        "        batch_size, n, a, t = x.shape\n",
        "\n",
        "        input_time_window = a if t == self.patch_size else t\n",
        "\n",
        "        x = self.patch_embed(x)\n",
        "        #print(x.shape)\n",
        "\n",
        "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)  # stole cls_tokens impl from Phil Wang, thanks\n",
        "\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "\n",
        "        pos_embed_used = self.pos_embed[:, input_chans] if input_chans is not None else self.pos_embed\n",
        "        num_pos = n if t == self.patch_size else input_time_window\n",
        "        if self.pos_embed is not None:\n",
        "            pos_embed = pos_embed_used[:, 1:num_pos+1, :].unsqueeze(2).expand(batch_size, -1, input_time_window, -1).flatten(1, 2)\n",
        "            pos_embed = torch.cat((pos_embed_used[:,0:1,:].expand(batch_size, -1, -1), pos_embed), dim=1)\n",
        "            #print(pos_embed.shape)\n",
        "            x = x + pos_embed\n",
        "\n",
        "\n",
        "        if self.time_embed is not None:\n",
        "            nc = n if t == self.patch_size else a\n",
        "            time_embed = self.time_embed[:, 0:input_time_window, :].unsqueeze(1).expand(batch_size, nc, -1, -1).flatten(1, 2)\n",
        "            x[:, 1:, :] += time_embed\n",
        "\n",
        "        x = self.pos_drop(x)\n",
        "\n",
        "        for blk in self.blocks:\n",
        "            x = blk(x, rel_pos_bias=None)\n",
        "\n",
        "        x = self.norm(x)\n",
        "        if self.fc_norm is not None:\n",
        "            if return_all_tokens:\n",
        "                return self.fc_norm(x)\n",
        "            t = x[:, 1:, :]\n",
        "            if return_patch_tokens:\n",
        "                return self.fc_norm(t)\n",
        "            else:\n",
        "                return self.fc_norm(t.mean(1))\n",
        "        else:\n",
        "            if return_all_tokens:\n",
        "                return x\n",
        "            elif return_patch_tokens:\n",
        "                return x[:, 1:]\n",
        "            else:\n",
        "                return x[:, 0]\n",
        "\n",
        "    def forward(self, x, input_chans=None, return_patch_tokens=False, return_all_tokens=False, **kwargs):\n",
        "        '''\n",
        "        x: [batch size, number of electrodes, number of patches, patch size]\n",
        "        For example, for an EEG sample of 4 seconds with 64 electrodes, x will be [batch size, 64, 4, 200]\n",
        "        '''\n",
        "        x = self.forward_features(x, input_chans=input_chans, return_patch_tokens=return_patch_tokens, return_all_tokens=return_all_tokens, **kwargs)\n",
        "        if return_patch_tokens:\n",
        "            return x, self.head(x.mean(1))\n",
        "        x = self.head(x)\n",
        "        return x\n",
        "\n",
        "    def forward_intermediate(self, x, layer_id=12, norm_output=False):\n",
        "        x = self.patch_embed(x)\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "\n",
        "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)  # stole cls_tokens impl from Phil Wang, thanks\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        if self.pos_embed is not None:\n",
        "            pos_embed = self.pos_embed[:, 1:, :].unsqueeze(2).expand(batch_size, -1, self.time_window, -1).flatten(1, 2)\n",
        "            pos_embed = torch.cat((self.pos_embed[:,0:1,:].expand(batch_size, -1, -1), pos_embed), dim=1)\n",
        "            x = x + pos_embed\n",
        "        if self.time_embed is not None:\n",
        "            time_embed = self.time_embed.unsqueeze(1).expand(batch_size, 62, -1, -1).flatten(1, 2)\n",
        "            x[:, 1:, :] += time_embed\n",
        "        x = self.pos_drop(x)\n",
        "\n",
        "        rel_pos_bias = self.rel_pos_bias() if self.rel_pos_bias is not None else None\n",
        "        if isinstance(layer_id, list):\n",
        "            output_list = []\n",
        "            for l, blk in enumerate(self.blocks):\n",
        "                x = blk(x, rel_pos_bias=rel_pos_bias)\n",
        "                # use last norm for all intermediate layers\n",
        "                if l in layer_id:\n",
        "                    if norm_output:\n",
        "                        x_norm = self.fc_norm(self.norm(x[:, 1:]))\n",
        "                        output_list.append(x_norm)\n",
        "                    else:\n",
        "                        output_list.append(x[:, 1:])\n",
        "            return output_list\n",
        "        elif isinstance(layer_id, int):\n",
        "            for l, blk in enumerate(self.blocks):\n",
        "                if l < layer_id:\n",
        "                    x = blk(x, rel_pos_bias=rel_pos_bias)\n",
        "                elif l == layer_id:\n",
        "                    x = blk.norm1(x)\n",
        "                else:\n",
        "                    break\n",
        "            return x[:, 1:]\n",
        "        else:\n",
        "            raise NotImplementedError(f\"Not support for layer id is {layer_id} now!\")\n",
        "\n",
        "    def get_intermediate_layers(self, x, use_last_norm=False):\n",
        "        x = self.patch_embed(x)\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "        #print(x.shape)\n",
        "\n",
        "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)  # stole cls_tokens impl from Phil Wang, thanks\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        if self.pos_embed is not None:\n",
        "            pos_embed = self.pos_embed[:, 1:, :].unsqueeze(2).expand(batch_size, -1, self.time_window, -1).flatten(1, 2)\n",
        "            pos_embed = torch.cat((self.pos_embed[:,0:1,:].expand(batch_size, -1, -1), pos_embed), dim=1)\n",
        "            #print(pos_embed.shape)\n",
        "            x = x + pos_embed\n",
        "        if self.time_embed is not None:\n",
        "            time_embed = self.time_embed.unsqueeze(1).expand(batch_size, 62, -1, -1).flatten(1, 2)\n",
        "            x[:, 1:, :] += time_embed\n",
        "        x = self.pos_drop(x)\n",
        "\n",
        "        features = []\n",
        "        rel_pos_bias = self.rel_pos_bias() if self.rel_pos_bias is not None else None\n",
        "        for blk in self.blocks:\n",
        "            x = blk(x, rel_pos_bias)\n",
        "            if use_last_norm:\n",
        "                features.append(self.norm(x))\n",
        "            else:\n",
        "                features.append(x)\n",
        "\n",
        "        return features\n"
      ],
      "metadata": {
        "id": "FR0HcAbmhjda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_state_dict(model, state_dict, prefix='', ignore_missing=\"relative_position_index\"):\n",
        "    missing_keys = []\n",
        "    unexpected_keys = []\n",
        "    error_msgs = []\n",
        "    # copy state_dict so _load_from_state_dict can modify it\n",
        "    metadata = getattr(state_dict, '_metadata', None)\n",
        "    state_dict = state_dict.copy()\n",
        "    if metadata is not None:\n",
        "        state_dict._metadata = metadata\n",
        "\n",
        "    def load(module, prefix=''):\n",
        "        local_metadata = {} if metadata is None else metadata.get(\n",
        "            prefix[:-1], {})\n",
        "        module._load_from_state_dict(\n",
        "            state_dict, prefix, local_metadata, True, missing_keys, unexpected_keys, error_msgs)\n",
        "        for name, child in module._modules.items():\n",
        "            if child is not None:\n",
        "                load(child, prefix + name + '.')\n",
        "\n",
        "    load(model, prefix=prefix)\n",
        "\n",
        "    warn_missing_keys = []\n",
        "    ignore_missing_keys = []\n",
        "    for key in missing_keys:\n",
        "        keep_flag = True\n",
        "        for ignore_key in ignore_missing.split('|'):\n",
        "            if ignore_key in key:\n",
        "                keep_flag = False\n",
        "                break\n",
        "        if keep_flag:\n",
        "            warn_missing_keys.append(key)\n",
        "        else:\n",
        "            ignore_missing_keys.append(key)\n",
        "\n",
        "    missing_keys = warn_missing_keys\n",
        "\n",
        "    if len(missing_keys) > 0:\n",
        "        print(\"Weights of {} not initialized from pretrained model: {}\".format(\n",
        "            model.__class__.__name__, missing_keys))\n",
        "    if len(unexpected_keys) > 0:\n",
        "        print(\"Weights from pretrained model not used in {}: {}\".format(\n",
        "            model.__class__.__name__, unexpected_keys))\n",
        "    if len(ignore_missing_keys) > 0:\n",
        "        print(\"Ignored weights of {} not initialized from pretrained model: {}\".format(\n",
        "            model.__class__.__name__, ignore_missing_keys))\n",
        "    if len(error_msgs) > 0:\n",
        "        print('\\n'.join(error_msgs))"
      ],
      "metadata": {
        "id": "sobGpQM9Q_FN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_model(model_path,  num_classes=num_classes, random_init = False):\n",
        "\n",
        "  model = NeuralTransformer(\n",
        "        patch_size=patch_size, embed_dim=embed_dim, depth=12, num_heads=10, mlp_ratio=4, qk_norm=partial(nn.LayerNorm, eps=1e-6), qkv_bias=True,\n",
        "        norm_layer=partial(nn.LayerNorm, eps=1e-6), init_values=0.1, use_abs_pos_emb=True, num_classes=num_classes, out_chans=embed_dim, use_mean_pooling=True)\n",
        "\n",
        "  state_dict = torch.load(model_path, map_location=device)\n",
        "\n",
        "  #return model without pretraining weights\n",
        "  if random_init:\n",
        "    return model\n",
        "\n",
        "  checkpoint_model = state_dict\n",
        "\n",
        "  if (checkpoint_model is not None):\n",
        "      all_keys = list(checkpoint_model.keys())\n",
        "      new_dict = OrderedDict()\n",
        "      for key in all_keys:\n",
        "          if key.startswith('student.'):\n",
        "              new_dict[key[8:]] = checkpoint_model[key]\n",
        "          else:\n",
        "              pass\n",
        "      checkpoint_model = new_dict\n",
        "\n",
        "  state_dictn = model.state_dict()\n",
        "  for k in ['head.weight', 'head.bias']:\n",
        "      if k in checkpoint_model and checkpoint_model[k].shape != state_dictn[k].shape:\n",
        "          print(f\"Removing key {k} from pretrained checkpoint\")\n",
        "          del checkpoint_model[k]\n",
        "\n",
        "  all_keys = list(checkpoint_model.keys())\n",
        "  for key in all_keys:\n",
        "      if \"relative_position_index\" in key:\n",
        "          checkpoint_model.pop(key)\n",
        "\n",
        "  load_state_dict(model, checkpoint_model)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "GFSWcOUciwqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main_training_loop(base_directory, train_func, val_func, device, model_path):\n",
        "    results = []\n",
        "\n",
        "\n",
        "    #Pass both models to classifier model and do classifier training\n",
        "    #set random_init=True to train without pretrained model\n",
        "    classifier_model = init_model(model_path, random_init=False)\n",
        "\n",
        "    run = wandb.init(\n",
        "          project=\"Synth_finetune_ersp_werp_pt\",\n",
        "          config={\n",
        "              \"bs\": batch_size,\n",
        "              \"num_epochs\": num_epochs\n",
        "          },\n",
        "          name=f\"small_50epochs\"\n",
        "      )\n",
        "\n",
        "\n",
        "\n",
        "    trn_dl = DataLoader(train_ds, batch_size = batch_size, shuffle = True)\n",
        "    val_dl = DataLoader(val_ds, batch_size = batch_size, shuffle = False)\n",
        "\n",
        "    #criterion = nn.CrossEntropyLoss(weight=torch.tensor(weights, dtype=torch.float32, device=device))\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    optimizer = optim.Adam(classifier_model.parameters(), lr=1e-5, weight_decay = 0., betas = (0.9, 0.999))\n",
        "\n",
        "    scheduler = get_scheduler(\"linear\", optimizer, num_warmup_steps=10, num_training_steps=num_epochs*len(trn_dl))\n",
        "\n",
        "    per_epoch_val_acc = []\n",
        "    min_error = 100\n",
        "    best_model = None\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "      train_results = train_func(trn_dl, classifier_model, criterion, optimizer, scheduler, device)\n",
        "      val_results = val_func(val_dl, classifier_model, criterion, device)\n",
        "      wandb.log({\"train_loss\": train_results['loss'], \"train_acc\": train_results['acc'],\n",
        "                    \"val_loss\": val_results['loss'], \"val_acc\": val_results['acc']})\n",
        "\n",
        "      per_epoch_val_acc.append(val_results['acc'])\n",
        "\n",
        "      print(f\"Epoch {epoch+1}/{num_epochs} Train Loss: {train_results['loss']:.4f} Val Loss: {val_results['loss']:.4f} Val Acc: {val_results['acc']:.4f}\")\n",
        "\n",
        "      if val_results['loss'] < min_error:\n",
        "        min_error = val_results['loss']\n",
        "        best_model = copy.deepcopy(classifier_model)\n",
        "\n",
        "    results.append(\n",
        "        {\n",
        "          'train_loss': train_results['loss'],\n",
        "          'train_acc': train_results['acc'],\n",
        "          'val_loss': val_results['loss'],\n",
        "          'val_acc': np.max(per_epoch_val_acc) #Report the maximum accuracy as opposed to the last one\n",
        "      }\n",
        "    )\n",
        "    torch.cuda.empty_cache()\n",
        "    wandb.finish()\n",
        "    return results, best_model"
      ],
      "metadata": {
        "id": "qVHhimgmVAeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r, best_model = main_training_loop(BLAES_data_path, training, validation, device, model_path)"
      ],
      "metadata": {
        "id": "9LeshlGh_hfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.eval()"
      ],
      "metadata": {
        "id": "xVvMtU0Xy9wL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deeplift_model = captum.attr.DeepLift(best_model)"
      ],
      "metadata": {
        "id": "Cpml3E-DzFfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#choose input and target\n",
        "sample_idx = 5\n",
        "input = val_ds[sample_idx][0].unsqueeze(0).to(device)\n",
        "target = val_ds[sample_idx][1]\n",
        "\n",
        "input.requires_grad = True"
      ],
      "metadata": {
        "id": "_prpOYgEy_JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline = input*0"
      ],
      "metadata": {
        "id": "Y3RTl8fJy_Fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attributions, delta = deeplift_model.attribute(input, baseline, target=target, return_convergence_delta=True)"
      ],
      "metadata": {
        "id": "uE8DhwHDy_AV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attributions = attributions.squeeze(0)"
      ],
      "metadata": {
        "id": "VgUuznIuy-9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model(input)"
      ],
      "metadata": {
        "id": "qt3uuIOGgz4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target"
      ],
      "metadata": {
        "id": "ymQGvhP1g6Bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#obtain mean attribution for each patch\n",
        "mean_attributions = torch.mean(attributions, dim=-1)"
      ],
      "metadata": {
        "id": "Hc6058V71COi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_patch_with_high_attributions(mean_attributions, k):\n",
        "  #returns top k patches with highest positive attributions\n",
        "  idxs = torch.argsort(mean_attributions.reshape(-1), descending=True)\n",
        "  top_k = idxs[:k]\n",
        "\n",
        "  top_k = [(idx.item()//10, idx.item() - (idx.item()//10)*10) for idx in top_k]\n",
        "  return top_k"
      ],
      "metadata": {
        "id": "7CNK0qYYQR3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get indices for patches with highest attribution\n",
        "#question is if these indices match with patches that we expect to have highest positive attribution\n",
        "patch_idxs = get_patch_with_high_attributions(mean_attributions, 5)"
      ],
      "metadata": {
        "id": "ZyxbV7fK1ObK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#first index is channel index, second is time index\n",
        "patch_idxs"
      ],
      "metadata": {
        "id": "XToHiXu_hhqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_attributions = attributions.reshape(19, -1) #flatten attr"
      ],
      "metadata": {
        "id": "d5WyXbytnkiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#choose channel from patch_idxs\n",
        "ch = 16"
      ],
      "metadata": {
        "id": "sX7zygqFnue8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(np.arange(5000)/500, original_attributions[ch].cpu().detach().numpy())\n",
        "plt.xlabel(\"Time(s)\")"
      ],
      "metadata": {
        "id": "-RS7YnEKg9Xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------\n",
        "# Large Brain Model for Learning Generic Representations with Tremendous EEG Data in BCI\n",
        "# By Wei-Bang Jiang\n",
        "# Based on BEiT-v2, timm, DeiT, and DINO code bases\n",
        "# https://github.com/microsoft/unilm/tree/master/beitv2\n",
        "# https://github.com/rwightman/pytorch-image-models/tree/master/timm\n",
        "# https://github.com/facebookresearch/deit/\n",
        "# https://github.com/facebookresearch/dino\n",
        "# ---------------------------------------------------------\n",
        "import math\n",
        "import sys\n",
        "from typing import Iterable, Optional\n",
        "import torch\n",
        "from timm.utils import ModelEma\n",
        "import LaBraM.utils as utils\n",
        "from einops import rearrange\n",
        "\n",
        "def train_class_batch(model, samples, target, criterion, ch_names):\n",
        "    outputs = model(samples, ch_names)\n",
        "    loss = criterion(outputs, target)\n",
        "    return loss, outputs\n",
        "\n",
        "\n",
        "def get_loss_scale_for_deepspeed(model):\n",
        "    optimizer = model.optimizer\n",
        "    return optimizer.loss_scale if hasattr(optimizer, \"loss_scale\") else optimizer.cur_scale\n",
        "\n",
        "\n",
        "def train_one_epoch(model: torch.nn.Module, criterion: torch.nn.Module,\n",
        "                    data_loader: Iterable, optimizer: torch.optim.Optimizer,\n",
        "                    device: torch.device, epoch: int, loss_scaler, max_norm: float = 0,\n",
        "                    model_ema: Optional[ModelEma] = None, log_writer=None,\n",
        "                    start_steps=None, lr_schedule_values=None, wd_schedule_values=None,\n",
        "                    num_training_steps_per_epoch=None, update_freq=None, ch_names=None, is_binary=True):\n",
        "    input_chans = None\n",
        "    if ch_names is not None:\n",
        "        input_chans = utils.get_input_chans(ch_names)\n",
        "    model.train(True)\n",
        "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
        "    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
        "    metric_logger.add_meter('min_lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
        "    header = 'Epoch: [{}]'.format(epoch)\n",
        "    print_freq = 10\n",
        "\n",
        "    if loss_scaler is None:\n",
        "        model.zero_grad()\n",
        "        model.micro_steps = 0\n",
        "    else:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    for data_iter_step, (samples, targets) in enumerate(metric_logger.log_every(data_loader, print_freq, header)):\n",
        "        step = data_iter_step // update_freq\n",
        "        if step >= num_training_steps_per_epoch:\n",
        "            continue\n",
        "        it = start_steps + step  # global training iteration\n",
        "        # Update LR & WD for the first acc\n",
        "        if lr_schedule_values is not None or wd_schedule_values is not None and data_iter_step % update_freq == 0:\n",
        "            for i, param_group in enumerate(optimizer.param_groups):\n",
        "                if lr_schedule_values is not None:\n",
        "                    param_group[\"lr\"] = lr_schedule_values[it] * param_group.get(\"lr_scale\", 1.0)\n",
        "                if wd_schedule_values is not None and param_group[\"weight_decay\"] > 0:\n",
        "                    param_group[\"weight_decay\"] = wd_schedule_values[it]\n",
        "\n",
        "        samples = samples.float().to(device, non_blocking=True)\n",
        "        #samples = rearrange(samples, 'B N (A T) -> B N A T', T=200)\n",
        "\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "        if is_binary:\n",
        "            targets = targets.float().unsqueeze(-1)\n",
        "\n",
        "        if loss_scaler is None:\n",
        "            samples = samples.half()\n",
        "            loss, output = train_class_batch(\n",
        "                model, samples, targets, criterion, input_chans)\n",
        "        else:\n",
        "            with torch.cuda.amp.autocast(enabled=False):\n",
        "                loss, output = train_class_batch(\n",
        "                    model, samples, targets, criterion, input_chans)\n",
        "\n",
        "        loss_value = loss.item()\n",
        "\n",
        "        if not math.isfinite(loss_value):\n",
        "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
        "            sys.exit(1)\n",
        "\n",
        "        if loss_scaler is None:\n",
        "            loss /= update_freq\n",
        "            model.backward(loss)\n",
        "            model.step()\n",
        "\n",
        "            if (data_iter_step + 1) % update_freq == 0:\n",
        "                # model.zero_grad()\n",
        "                # Deepspeed will call step() & model.zero_grad() automatic\n",
        "                if model_ema is not None:\n",
        "                    model_ema.update(model)\n",
        "            grad_norm = None\n",
        "            #loss_scale_value = get_loss_scale_for_deepspeed(model)\n",
        "        else:\n",
        "            # this attribute is added by timm on one optimizer (adahessian)\n",
        "            is_second_order = hasattr(optimizer, 'is_second_order') and optimizer.is_second_order\n",
        "            loss /= update_freq\n",
        "            grad_norm = loss_scaler(loss, optimizer, clip_grad=max_norm,\n",
        "                                    parameters=model.parameters(), create_graph=is_second_order,\n",
        "                                    update_grad=(data_iter_step + 1) % update_freq == 0)\n",
        "            if (data_iter_step + 1) % update_freq == 0:\n",
        "                optimizer.zero_grad()\n",
        "                if model_ema is not None:\n",
        "                    model_ema.update(model)\n",
        "            #loss_scale_value = loss_scaler.state_dict()[\"scale\"]\n",
        "\n",
        "        #torch.cuda.synchronize()\n",
        "\n",
        "        if is_binary:\n",
        "            class_acc = utils.get_metrics(torch.sigmoid(output).detach().cpu().numpy(), targets.detach().cpu().numpy(), [\"accuracy\"], is_binary)[\"accuracy\"]\n",
        "        else:\n",
        "            class_acc = (output.max(-1)[-1] == targets.squeeze()).float().mean()\n",
        "\n",
        "        metric_logger.update(loss=loss_value)\n",
        "        metric_logger.update(class_acc=class_acc)\n",
        "        #metric_logger.update(loss_scale=loss_scale_value)\n",
        "        min_lr = 10.\n",
        "        max_lr = 0.\n",
        "        for group in optimizer.param_groups:\n",
        "            min_lr = min(min_lr, group[\"lr\"])\n",
        "            max_lr = max(max_lr, group[\"lr\"])\n",
        "\n",
        "        metric_logger.update(lr=max_lr)\n",
        "        metric_logger.update(min_lr=min_lr)\n",
        "        weight_decay_value = None\n",
        "        for group in optimizer.param_groups:\n",
        "            if group[\"weight_decay\"] > 0:\n",
        "                weight_decay_value = group[\"weight_decay\"]\n",
        "        metric_logger.update(weight_decay=weight_decay_value)\n",
        "        metric_logger.update(grad_norm=grad_norm)\n",
        "\n",
        "        if log_writer is not None:\n",
        "            log_writer.update(loss=loss_value, head=\"loss\")\n",
        "            log_writer.update(class_acc=class_acc, head=\"loss\")\n",
        "            #log_writer.update(loss_scale=loss_scale_value, head=\"opt\")\n",
        "            log_writer.update(lr=max_lr, head=\"opt\")\n",
        "            log_writer.update(min_lr=min_lr, head=\"opt\")\n",
        "            log_writer.update(weight_decay=weight_decay_value, head=\"opt\")\n",
        "            log_writer.update(grad_norm=grad_norm, head=\"opt\")\n",
        "\n",
        "            log_writer.set_step()\n",
        "\n",
        "    # gather the stats from all processes\n",
        "    #metric_logger.synchronize_between_processes()\n",
        "    print(\"Averaged stats:\", metric_logger)\n",
        "    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(data_loader, model, device, header='Test:', ch_names=None, metrics=['acc'], is_binary=True):\n",
        "    input_chans = None\n",
        "    if ch_names is not None:\n",
        "        input_chans = utils.get_input_chans(ch_names)\n",
        "    if is_binary:\n",
        "        criterion = torch.nn.BCEWithLogitsLoss()\n",
        "    else:\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
        "    #header = 'Test:'\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "    pred = []\n",
        "    true = []\n",
        "    for step, batch in enumerate(metric_logger.log_every(data_loader, 10, header)):\n",
        "        EEG = batch[0]\n",
        "        target = batch[-1]\n",
        "        EEG = EEG.float().to(device, non_blocking=True)\n",
        "        #EEG = rearrange(EEG, 'B N (A T) -> B N A T', T=200)\n",
        "        target = target.to(device, non_blocking=True)\n",
        "        if is_binary:\n",
        "            target = target.float().unsqueeze(-1)\n",
        "\n",
        "        # compute output\n",
        "        with torch.cuda.amp.autocast(enabled=False):\n",
        "            output = model(EEG, input_chans=input_chans)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "        if is_binary:\n",
        "            output = torch.sigmoid(output).cpu()\n",
        "        else:\n",
        "            output = output.cpu()\n",
        "        target = target.cpu()\n",
        "\n",
        "        results = utils.get_metrics(output.numpy(), target.numpy(), metrics, is_binary)\n",
        "        pred.append(output)\n",
        "        true.append(target)\n",
        "\n",
        "        batch_size = EEG.shape[0]\n",
        "        metric_logger.update(loss=loss.item())\n",
        "        for key, value in results.items():\n",
        "            metric_logger.meters[key].update(value, n=batch_size)\n",
        "        #metric_logger.meters['acc5'].update(acc5.item(), n=batch_size)\n",
        "    # gather the stats from all processes\n",
        "    #metric_logger.synchronize_between_processes()\n",
        "    print('* loss {losses.global_avg:.3f}'\n",
        "          .format(losses=metric_logger.loss))\n",
        "\n",
        "    pred = torch.cat(pred, dim=0).numpy()\n",
        "    true = torch.cat(true, dim=0).numpy()\n",
        "\n",
        "    ret = utils.get_metrics(pred, true, metrics, is_binary, 0.5)\n",
        "    ret['loss'] = metric_logger.loss.global_avg\n",
        "    return ret, (pred, true)"
      ],
      "metadata": {
        "id": "BZ3_VZPtUcIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from optim_factory import create_optimizer"
      ],
      "metadata": {
        "id": "0eYdeEHfampi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_train(args, model,  dataset_train_ls, dataset_val_ls, device):\n",
        "  some_res = []\n",
        "  log_writer = utils.TensorboardLogger(log_dir=args.log_dir)\n",
        "  model.to(device)\n",
        "  #num_training_steps_per_epoch = math.ceil(sum([len(dataset) for dataset in dataset_train_ls]) / args.batch_size)\n",
        "\n",
        "  data_loader_train = torch.utils.data.DataLoader(\n",
        "      dataset_train_ls[0],\n",
        "      batch_size=args.batch_size,\n",
        "      pin_memory=args.pin_mem,\n",
        "      drop_last=False,\n",
        "      shuffle=True,\n",
        "  )\n",
        "  data_loader_val = torch.utils.data.DataLoader(\n",
        "            dataset_val_ls[0],\n",
        "            batch_size=args.batch_size,\n",
        "            pin_memory=args.pin_mem,\n",
        "            drop_last=False,\n",
        "            shuffle=False\n",
        "        )\n",
        "\n",
        "  model.to(device)\n",
        "\n",
        "  model_ema = timm.utils.ModelEma(\n",
        "            model,\n",
        "            decay=args.model_ema_decay,\n",
        "            device=device)\n",
        "  n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "  total_batch_size = args.batch_size * args.update_freq\n",
        "  num_training_steps_per_epoch = len(dataset_train_ls[0]) // total_batch_size\n",
        "\n",
        "  assigner = None\n",
        "\n",
        "  num_layers = model.get_num_layers()\n",
        "\n",
        "  skip_weight_decay_list = model.no_weight_decay()\n",
        "  if args.disable_weight_decay_on_rel_pos_bias:\n",
        "      for i in range(num_layers):\n",
        "          skip_weight_decay_list.add(\"blocks.%d.attn.relative_position_bias_table\" % i)\n",
        "\n",
        "  optimizer = create_optimizer(\n",
        "            args, model, skip_list=skip_weight_decay_list,\n",
        "            get_num_layer=assigner.get_layer_id if assigner is not None else None,\n",
        "            get_layer_scale=assigner.get_scale if assigner is not None else None)\n",
        "  loss_scaler = utils.NativeScalerWithGradNormCount()\n",
        "\n",
        "  lr_schedule_values = utils.cosine_scheduler(\n",
        "        args.lr, args.min_lr, args.epochs, num_training_steps_per_epoch,\n",
        "        warmup_epochs=args.warmup_epochs, warmup_steps=args.warmup_steps,\n",
        "    )\n",
        "  if args.weight_decay_end is None:\n",
        "      args.weight_decay_end = args.weight_decay\n",
        "  wd_schedule_values = utils.cosine_scheduler(\n",
        "      args.weight_decay, args.weight_decay_end, args.epochs, num_training_steps_per_epoch)\n",
        "  print(\"Max WD = %.7f, Min WD = %.7f\" % (max(wd_schedule_values), min(wd_schedule_values)))\n",
        "\n",
        "  criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "  for epoch in range(args.epochs):\n",
        "    log_writer.set_step(epoch * num_training_steps_per_epoch * args.update_freq)\n",
        "\n",
        "    train_stats = train_one_epoch(\n",
        "            model, criterion, data_loader_train, optimizer,\n",
        "            device, epoch, loss_scaler, args.clip_grad, model_ema,\n",
        "            log_writer=log_writer, start_steps=epoch * num_training_steps_per_epoch,\n",
        "            lr_schedule_values=lr_schedule_values, wd_schedule_values=wd_schedule_values,\n",
        "            num_training_steps_per_epoch=num_training_steps_per_epoch, update_freq=args.update_freq,\n",
        "            ch_names=None, is_binary=True\n",
        "        )\n",
        "\n",
        "    metrics = [\"pr_auc\", \"roc_auc\", \"accuracy\", \"balanced_accuracy\"]\n",
        "\n",
        "    val_stats, r = evaluate(data_loader_val, model, device, header='Val:', ch_names=None, metrics=metrics, is_binary=True)\n",
        "    print(f\"Accuracy of the network on the {len(dataset_val_ls[0])} val EEG: {val_stats['accuracy']:.2f}%\")\n",
        "\n",
        "    some_res.append(r)\n",
        "\n",
        "    for key, value in val_stats.items():\n",
        "\n",
        "      if key == 'accuracy':\n",
        "          log_writer.update(accuracy=value, head=\"val\", step=epoch)\n",
        "      elif key == 'balanced_accuracy':\n",
        "          log_writer.update(balanced_accuracy=value, head=\"val\", step=epoch)\n",
        "      elif key == 'f1_weighted':\n",
        "          log_writer.update(f1_weighted=value, head=\"val\", step=epoch)\n",
        "      elif key == 'pr_auc':\n",
        "          log_writer.update(pr_auc=value, head=\"val\", step=epoch)\n",
        "      elif key == 'roc_auc':\n",
        "          log_writer.update(roc_auc=value, head=\"val\", step=epoch)\n",
        "      elif key == 'cohen_kappa':\n",
        "          log_writer.update(cohen_kappa=value, head=\"val\", step=epoch)\n",
        "      elif key == 'loss':\n",
        "          log_writer.update(loss=value, head=\"val\", step=epoch)\n",
        "\n",
        "\n",
        "    log_stats = {**{f'train_{k}': v for k, v in train_stats.items()},\n",
        "                         **{f'val_{k}': v for k, v in val_stats.items()},\n",
        "                         'epoch': epoch,\n",
        "                         'n_parameters': n_parameters}\n",
        "    if log_writer is not None:\n",
        "        log_writer.flush()\n",
        "    with open(os.path.join(args.output_dir, \"log.txt\"), mode=\"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(json.dumps(log_stats) + \"\\n\")\n",
        "\n",
        "  return some_res"
      ],
      "metadata": {
        "id": "L8kUAWQgUcEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "foundation_files, event_files, subjects = load_data(BLAES_data_path)"
      ],
      "metadata": {
        "id": "J-KIUCGNdehy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_ds = CustomBIPDataset(foundation_files[1:], event_files[1:])\n",
        "validation_ds = CustomBIPDataset([foundation_files[0]], [event_files[0]])"
      ],
      "metadata": {
        "id": "ycVEUgLedKAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = init_model(model_path, num_classes=1)"
      ],
      "metadata": {
        "id": "oZKZD5j2dwUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "some_res = do_train(args, model, [training_ds], [validation_ds], device)"
      ],
      "metadata": {
        "id": "xHI2iKQvf6jT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "153 - 129"
      ],
      "metadata": {
        "id": "sSQX_9mdmICw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score"
      ],
      "metadata": {
        "id": "EW6lezIzmgg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "129/153"
      ],
      "metadata": {
        "id": "lhJooswAmbDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "some_res[6][0]"
      ],
      "metadata": {
        "id": "sgVvYzlVhm_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RF"
      ],
      "metadata": {
        "id": "jhHx3chJs6OP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import signal\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "KgeZi9qrlspB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(8 – 13 Hz), beta (13 – 30 Hz), gamma (30 – 100 Hz), theta (4 – 8 Hz) and delta (1 – 4 Hz)"
      ],
      "metadata": {
        "id": "ZktPPItCuVBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_feature(path):\n",
        "\n",
        "  x = np.load(path)\n",
        "\n",
        "  sos_delta = signal.butter(6, [1, 4], btype='bandpass', fs=500, output='sos')\n",
        "  sos_theta = signal.butter(6, [4, 8], btype='bandpass', fs=500, output='sos')\n",
        "  sos_alpha = signal.butter(6, [8, 13], btype='bandpass', fs=500, output='sos')\n",
        "  sos_beta = signal.butter(6, [13, 30], btype='bandpass', fs=500, output='sos')\n",
        "  sos_gamma = signal.butter(6, [30, 100], btype='bandpass', fs=500, output='sos')\n",
        "\n",
        "  delta_signal = signal.sosfilt(sos_delta, x=x, axis=-1)\n",
        "  theta_signal = signal.sosfilt(sos_theta, x=x, axis=-1)\n",
        "  alpha_signal = signal.sosfilt(sos_alpha, x=x, axis=-1)\n",
        "  beta_signal = signal.sosfilt(sos_beta, x=x, axis=-1)\n",
        "  gamma_signal = signal.sosfilt(sos_gamma, x=x, axis=-1)\n",
        "\n",
        "  energy_delta = scipy.linalg.norm(delta_signal, ord=2, axis=1)\n",
        "  energy_theta = scipy.linalg.norm(theta_signal, ord=2, axis=1)\n",
        "  energy_alpha = scipy.linalg.norm(alpha_signal, ord=2, axis=1)\n",
        "  energy_beta = scipy.linalg.norm(beta_signal, ord=2, axis=1)\n",
        "  energy_gamma = scipy.linalg.norm(gamma_signal, ord=2, axis=1)\n",
        "\n",
        "  label = int(path.split('/')[-2].split('_')[0][-1])\n",
        "\n",
        "\n",
        "  return np.concatenate([energy_delta, energy_theta, energy_alpha, energy_beta, energy_gamma]), label\n",
        "  #return energy_beta, label"
      ],
      "metadata": {
        "id": "9WYxXfoQuHRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X, train_y = [], []\n",
        "for path in train_ds.items:\n",
        "  x, y = make_feature(path)\n",
        "  train_X.append(x)\n",
        "  train_y.append(y)"
      ],
      "metadata": {
        "id": "hbOwxOwvxtg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_X, val_y = [], []\n",
        "for path in val_ds.items:\n",
        "  x, y = make_feature(path)\n",
        "  val_X.append(x)\n",
        "  val_y.append(y)"
      ],
      "metadata": {
        "id": "26_wU0ony8nQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = np.array(train_X)\n",
        "train_y = np.array(train_y)\n",
        "val_X = np.array(val_X)\n",
        "val_y = np.array(val_y)"
      ],
      "metadata": {
        "id": "P86ZL4XpzNpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X.shape, train_y.shape, val_X.shape, val_y.shape"
      ],
      "metadata": {
        "id": "slcEYdhDzWht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(train_X, train_y)"
      ],
      "metadata": {
        "id": "GBlM9obSzZwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf.score(val_X, val_y)"
      ],
      "metadata": {
        "id": "x05At0WpzpLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NG5CyRdB4212"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}